for (i in 1:8){
if (sum(is.na(x[,i]))>0){
f = x[,i]
m = mean(f[!is.na(f)])
f[is.na(f)] = rep(m, sum(is.na(f)))
x[,i] = f
}
}
model <- lda(y~., data=x, CV=TRUE)
accuracy_score(model$class, y)
x <- x0
for (i in 1:dim(x)[2]){
if (sum(is.na(x[,i]))>0){
f = x[,i]
m = mean(f[!is.na(f)])
f[is.na(f)] = rep(m, sum(is.na(f)))
x[,i] = f
}
}
model <- lda(y~., data=x, CV=TRUE)
accuracy_score(model$class, y)
x <- x0
for (i in 1:dim(x)[2]){
if (sum(is.na(x[,i]))>0){
f = x[,i]
m = mean(f[!is.na(f)])
f[is.na(f)] = rep(m, sum(is.na(f)))
x[,i] = f
}
}
model <- lda(y~., data=x, CV=TRUE)
acc_mean <- accuracy_score(model$class, y)
x = x0
bool = NULL
for (i in 1:dim(x)[1]){
bool = c(bool, sum(is.na(x[i,]))==0)
}
model <- lda(y[bool]~., data=x[bool,], CV=TRUE)
accuracy_score(model$class, y[bool])
cat("The accuracy of this model is :", acc_0)
x = x0
bool = NULL
for (i in 1:dim(x)[1]){
bool = c(bool, sum(is.na(x[i,]))==0)
}
model <- lda(y[bool]~., data=x[bool,], CV=TRUE)
accuracy_score(model$class, y[bool])
cat("The accuracy of this model is :", acc_0)
x = x0
bool = NULL
for (i in 1:dim(x)[1]){
bool = c(bool, sum(is.na(x[i,]))==0)
}
model <- lda(y[bool]~., data=x[bool,], CV=TRUE)
acc_no_na <- accuracy_score(model$class, y[bool])
cat("The accuracy of this model is :", acc_no_na)
x <- x0
for (i in 1:dim(x)[2]){
if (sum(is.na(x[,i]))>0){
f = x[,i]
m = mean(f[!is.na(f)])
f[is.na(f)] = rep(m, sum(is.na(f)))
x[,i] = f
}
}
model <- lda(y~., data=x, CV=TRUE)
acc_mean <- accuracy_score(model$class, y)
cat("The accuracy of this model is :", acc_mean)
# replace NAs by 0
library(MASS)
model <- lda(y~., data=x, CV=TRUE)
acc_0 <- accuracy_score(model$class, y)
cat("The accuracy of this model is :", acc_0)
x = x0
bool = NULL
for (i in 1:dim(x)[1]){
bool = c(bool, sum(is.na(x[i,]))==0)
}
model <- lda(y[bool]~., data=x[bool,], CV=TRUE)
acc_no_na <- accuracy_score(model$class, y[bool])
cat("The accuracy of this model is :", acc_no_na)
x = x0
bool = NULL
for (i in 1:dim(x)[1]){
bool = c(bool, sum(is.na(x[i,]))==0)
}
model <- lda(y[bool]~., data=x[bool,], CV=TRUE)
acc_no_na <- accuracy_score(model$class, y[bool])
cat("The accuracy of this model is :", acc_no_na)
x = x0
bool = NULL
for (i in 1:dim(x)[1]){
bool = c(bool, sum(is.na(x[i,]))==0)
}
model <- lda(y[bool]~., data=x[bool,], CV=TRUE)
acc_no_na <- accuracy_score(model$class, y[bool])
cat("The accuracy of this model is :", acc_no_na)
x = x0
bool = NULL
for (i in 1:dim(x)[1]){
bool = c(bool, sum(is.na(x[i,]))==0)
}
model <- lda(y[bool]~., data=x[bool,], CV=TRUE)
acc_no_na <- accuracy_score(model$class, y[bool])
cat("The accuracy of this model is :", acc_no_na)
x = x0
bool = NULL
for (i in 1:dim(x)[1]){
bool = c(bool, sum(is.na(x[i,]))==0)
}
model <- lda(y[bool]~., data=x[bool,], CV=TRUE)
acc_no_na <- accuracy_score(model$class, y[bool])
cat("The accuracy of this model is :", acc_no_na)
# replace NAs by 0
x0 <- x
x[is.na(x)] = rep(0, sum(is.na(x)))
source('aux_functions.r')
x = PimaIndiansDiabetes2[,-9]
y = PimaIndiansDiabetes2[,9]
y = negative_positive_class_labels(y)
# replace NAs by 0
x0 <- x
x[is.na(x)] = rep(0, sum(is.na(x)))
# replace NAs by 0
library(MASS)
model <- lda(y~., data=x, CV=TRUE)
acc_0 <- accuracy_score(model$class, y)
cat("The accuracy of this model is :", acc_0)
x <- x0
for (i in 1:dim(x)[2]){
if (sum(is.na(x[,i]))>0){
f = x[,i]
m = mean(f[!is.na(f)])
f[is.na(f)] = rep(m, sum(is.na(f)))
x[,i] = f
}
}
model <- lda(y~., data=x, CV=TRUE)
acc_mean <- accuracy_score(model$class, y)
cat("The accuracy of this model is :", acc_mean)
x = x0
bool = NULL
for (i in 1:dim(x)[1]){
bool = c(bool, sum(is.na(x[i,]))==0)
}
model <- lda(y[bool]~., data=x[bool,], CV=TRUE)
acc_no_na <- accuracy_score(model$class, y[bool])
cat("The accuracy of this model is :", acc_no_na)
# Visualization of results
accuracy <- c(acc_0, acc_mean, acc_no_na)
names <- c("NA with 0", "NA with mean", "Observations without NA")
ylim <- c(0, 1.1*max(accuracy))
ax <- barplot(accuracy,beside=T,col=c("#F7D358"), names=names, ylim=ylim,
main = "Accuracy of the three models",
ylab="Accuracy")
text(x=ax, y<-number, label=number, pos = 3, cex = 0.8, col = "red")
# Visualization of results
accuracy <- c(acc_0, acc_mean, acc_no_na)
names <- c("NA with 0", "NA with mean", "Observations without NA")
ylim <- c(0, 1.1*max(accuracy))
ax <- barplot(accuracy,beside=T,col=c("#F7D358"), names=names, ylim=ylim,
main = "Accuracy of the three models",
ylab="Accuracy")
text(x=ax, y<-number, label=accuracy, pos = 3, cex = 0.8, col = "red")
# Visualization of results
accuracy <- c(acc_0, acc_mean, acc_no_na)
names <- c("NA with 0", "NA with mean", "Observations without NA")
ylim <- c(0, 1.1*max(accuracy))
ax <- barplot(accuracy,beside=T,col=c("#F7D358"), names=names, ylim=ylim,
main = "Accuracy of the three models",
ylab="Accuracy")
text(x=ax, y<-accuracy, label=accuracy, pos = 3, cex = 0.8, col = "red")
# Visualization of results
accuracy <- c(acc_0, acc_mean, acc_no_na)
names <- c("NA with 0", "NA with mean", "Observations without NA")
ylim <- c(0, 1.5*max(accuracy))
ax <- barplot(accuracy,beside=T,col=c("#F7D358"), names=names, ylim=ylim,
main = "Accuracy of the three models",
ylab="Accuracy")
text(x=ax, y<-accuracy, label=accuracy, pos = 3, cex = 0.8, col = "red")
# Visualization of results
accuracy <- c(acc_0, acc_mean, acc_no_na)
names <- c("NA with 0", "NA with mean", "Observations without NA")
ylim <- c(0, 1.5*max(accuracy))
ax <- barplot(accuracy,beside=T,col=c("red"), names=names, ylim=ylim,
main = "Accuracy of the three models",
ylab="Accuracy")
text(x=ax, y<-accuracy, label=accuracy, pos = 3, cex = 0.8, col = "red")
# Visualization of results
accuracy <- c(acc_0, acc_mean, acc_no_na)
names <- c("NA with 0", "NA with mean", "Observations without NA")
ylim <- c(0, 1.5*max(accuracy))
ax <- barplot(accuracy,beside=T,col=c("red", "red", "green"), names=names, ylim=ylim,
main = "Accuracy of the three models",
ylab="Accuracy")
text(x=ax, y<-accuracy, label=accuracy, pos = 3, cex = 0.8, col = "red")
# Visualization of results
accuracy <- c(acc_0, acc_mean, acc_no_na)
names <- c("NA with 0", "NA with mean", "Observation")
ylim <- c(0, 1.5*max(accuracy))
ax <- barplot(accuracy,beside=T,col=c("red", "red", "green"), names=names, ylim=ylim,
main = "Accuracy of the three models",
ylab="Accuracy")
text(x=ax, y<-accuracy, label=accuracy, pos = 3, cex = 0.8, col = "red")
# Visualization of results
accuracy <- c(acc_0, acc_mean, acc_no_na)
names <- c("NA with 0", "NA with mean", "lines without NA")
ylim <- c(0, 1.5*max(accuracy))
ax <- barplot(accuracy,beside=T,col=c("red", "red", "green"), names=names, ylim=ylim,
main = "Accuracy of the three models",
ylab="Accuracy")
text(x=ax, y<-accuracy, label=accuracy, pos = 3, cex = 0.8, col = "red")
# Visualization of results
accuracy <- c(acc_0, acc_mean, acc_no_na)
names <- c("NA with 0", "NA with mean", "lines without NA")
ylim <- c(0, 1.5*max(accuracy))
ax <- barplot(accuracy,beside=T,col=c("red", "red", "green"), names=names, ylim=ylim,
main = "Accuracy of the three models",
ylab="Accuracy")
text(x=ax, y<-accuracy, label=accuracy, pos = 3, cex = 0.8, col = "blue")
x <- x_best
source('aux_functions.r')
x = PimaIndiansDiabetes2[,-9]
y = PimaIndiansDiabetes2[,9]
y = negative_positive_class_labels(y)
# replace NAs by 0
x0 <- x
x[is.na(x)] = rep(0, sum(is.na(x)))
# replace NAs by 0
library(MASS)
model <- lda(y~., data=x, CV=TRUE)
acc_0 <- accuracy_score(model$class, y)
x_best <- x
y_best <- y
cat("The accuracy of this model is :", acc_0)
x <- x0
for (i in 1:dim(x)[2]){
if (sum(is.na(x[,i]))>0){
f = x[,i]
m = mean(f[!is.na(f)])
f[is.na(f)] = rep(m, sum(is.na(f)))
x[,i] = f
}
}
model <- lda(y~., data=x, CV=TRUE)
acc_mean <- accuracy_score(model$class, y)
cat("The accuracy of this model is :", acc_mean)
x = x0
bool = NULL
for (i in 1:dim(x)[1]){
bool = c(bool, sum(is.na(x[i,]))==0)
}
model <- lda(y[bool]~., data=x[bool,], CV=TRUE)
acc_no_na <- accuracy_score(model$class, y[bool])
cat("The accuracy of this model is :", acc_no_na)
# Visualization of results
accuracy <- c(acc_0, acc_mean, acc_no_na)
names <- c("NA with 0", "NA with mean", "lines without NA")
ylim <- c(0, 1.5*max(accuracy))
ax <- barplot(accuracy,beside=T,col=c("red", "red", "green"), names=names, ylim=ylim,
main = "Accuracy of the three models",
ylab="Accuracy")
text(x=ax, y<-accuracy, label=accuracy, pos = 3, cex = 0.8, col = "blue")
x = x[bool,]
y = y[bool]
x <- x_best
y <- y_best
library(caret)
folds = createFolds(y, 10)
y_split = lapply(folds, function(ind, dat) dat[ind], dat = y)
x_split <- lapply(folds, function(ind, dat) dat[ind,], dat = x)
library(caret)
folds = createFolds(y, 10)
y_split = lapply(folds, function(ind, dat) dat[ind], dat = y)
x_split <- lapply(folds, function(ind, dat) dat[ind,], dat = x)
library(class)
CV <- function(my_model){
accs = NULL
for (i in 1:10){
x_test = x_split[i][[1]]
y_test = y_split[i][[1]]
x_train = NULL
y_train = NULL
for (el in x_split[-i]){
x_train = rbind(x_train, el)
}
for (el in y_split[-i]){
y_train = c(y_train, el)
}
y_pred = my_model(x_train, y_train, x_test)
accs = c(accs, accuracy_score(y_pred, y_test))
}
return (accs)
}
model_lda <- function(x_train, y_train, x_test){
model <- lda(y_train~., data=x_train)
y_pred = predict(model, newdata=x_test)$class
return(y_pred)
}
model_knn1 <- function(x_train, y_train, x_test) {
return (knn(x_train, x_test, y_train, k=1, prob=TRUE))
}
model_knn5 <- function(x_train, y_train, x_test) {
return (knn(x_train, x_test, y_train, k=5, prob=TRUE))
}
model_knn10 <- function(x_train, y_train, x_test) {
return (knn(x_train, x_test, y_train, k=10, prob=TRUE))
}
model_perceptron <- function(x_train, y_train, x_test) {
per = perceptron(x_train, y_train)
return (predict.perceptron(per, x_test))
}
models = c(model_lda, model_knn1, model_knn5, model_knn10, model_perceptron)
res = sapply(models, function(x) return(CV(x)))
noms = c("lda", "knn1", "knn5", "knn10", "perceptron")
accs = sapply(1:5, function(x) return(mean(res[,x])))
sds = sapply(1:5, function(x) return(sd(res[,x])))
data.frame(noms, accs, sds)
pvalues <- sapply(2:5, function(i) return(t.test(res[,1], res[,i], alternative = "two.sided", var.equal = FALSE)$p.value))
pvalues
knitr::opts_chunk$set(echo = TRUE)
# Visualization of results
accuracy <- c(acc_0, acc_mean, acc_no_na)
knitr::opts_chunk$set(echo = TRUE)
library(mlbench)
data(PimaIndiansDiabetes2)
set.seed(0)
total <- 0
missing <- c()
number <- c()
for (i in 1 : dim(PimaIndiansDiabetes2)[2]){
# the number of missing values in each column
nb_missing <- sum(is.na(PimaIndiansDiabetes2[,i]))
if (nb_missing > 0){
# feature that has missing values
feature <- names(PimaIndiansDiabetes2)[i]
missing <- c(missing, feature)
#cat(feature)
#cat(" : ")
# the number of missing values in that feature
number <- c(number, nb_missing)
#cat(number)
#cat("\n")
total = total  + nb_missing
}
}
# Visualization of results
ylim <- c(0, 1.1*max(number))
ax <- barplot(number,beside=T,col=c("#F7D358"), names=missing, ylim=ylim,
main = "Features that have missing values",
ylab="number of missing values")
text(x=ax, y<-number, label=number, pos = 3, cex = 0.8, col = "red")
cat("With a total missing values of :", total)
positive <- sum(PimaIndiansDiabetes2$diabetes=='pos')
cat("We have :", positive, "positive examples.")
# Two possible methods:
negative <- sum(PimaIndiansDiabetes2$diabetes=='neg')
negative <- dim(PimaIndiansDiabetes2)[1] - positive
cat("We have :", negative, "negative examples.")
# Visualization of results
y <- c(positive, negative)
names <- c("postive", "negative")
col <- c("green", "red")
ylim <- c(0, 1.1*max(y))
ax <- barplot(y,beside=T,col=col, names=names, ylim=ylim,
main = "positive and negative examples in the dataset")
text(x=ax, y<-y, label=y, pos = 3, cex = 0.8, col = col)
source('aux_functions.r')
x = PimaIndiansDiabetes2[,-9]
y = PimaIndiansDiabetes2[,9]
y = negative_positive_class_labels(y)
accuracy_score <- function(y_true, y_pred){
if (length(y_true)==length(y_pred))
{
return(sum(y_pred==y_true)/length(y_true))
}
else
{
stop("ERROR : vectors must be of equal length")
}
}
y_pred = rep(-1, length(y))
dummy_acc <- accuracy_score(y, y_pred)
cat("The accuracy of a dummy classifier is :", dummy_acc)
# replace NAs by 0
x0 <- x
x[is.na(x)] = rep(0, sum(is.na(x)))
# replace NAs by 0
library(MASS)
model <- lda(y~., data=x, CV=TRUE)
acc_0 <- accuracy_score(model$class, y)
x_best <- x
y_best <- y
cat("The accuracy of this model is :", acc_0)
x <- x0
for (i in 1:dim(x)[2]){
if (sum(is.na(x[,i]))>0){
f = x[,i]
m = mean(f[!is.na(f)])
f[is.na(f)] = rep(m, sum(is.na(f)))
x[,i] = f
}
}
model <- lda(y~., data=x, CV=TRUE)
acc_mean <- accuracy_score(model$class, y)
cat("The accuracy of this model is :", acc_mean)
x = x0
bool = NULL
for (i in 1:dim(x)[1]){
bool = c(bool, sum(is.na(x[i,]))==0)
}
model <- lda(y[bool]~., data=x[bool,], CV=TRUE)
acc_no_na <- accuracy_score(model$class, y[bool])
cat("The accuracy of this model is :", acc_no_na)
# Visualization of results
accuracy <- c(acc_0, acc_mean, acc_no_na)
names <- c("NA -> 0", "NA -> mean", "removing NA")
#ylim <- c(0, 1.5*max(accuracy))
#ax <- barplot(accuracy,beside=T,col=c("red", "red", "green"), names=names, ylim=ylim,
#              main = "Accuracy of the three models",
#              ylab="Accuracy")
#text(x=ax, y<-accuracy, label=accuracy, pos = 3, cex = 0.8, col = "blue")
data.frame(names, accuracy)
x <- x_best
y <- y_best
library(caret)
folds = createFolds(y, 10)
y_split = lapply(folds, function(ind, dat) dat[ind], dat = y)
x_split <- lapply(folds, function(ind, dat) dat[ind,], dat = x)
library(class)
CV <- function(my_model){
accs = NULL
for (i in 1:10){
x_test = x_split[i][[1]]
y_test = y_split[i][[1]]
x_train = NULL
y_train = NULL
for (el in x_split[-i]){
x_train = rbind(x_train, el)
}
for (el in y_split[-i]){
y_train = c(y_train, el)
}
y_pred = my_model(x_train, y_train, x_test)
accs = c(accs, accuracy_score(y_pred, y_test))
}
return (accs)
}
model_lda <- function(x_train, y_train, x_test){
model <- lda(y_train~., data=x_train)
y_pred = predict(model, newdata=x_test)$class
return(y_pred)
}
model_knn1 <- function(x_train, y_train, x_test) {
return (knn(x_train, x_test, y_train, k=1, prob=TRUE))
}
model_knn5 <- function(x_train, y_train, x_test) {
return (knn(x_train, x_test, y_train, k=5, prob=TRUE))
}
model_knn10 <- function(x_train, y_train, x_test) {
return (knn(x_train, x_test, y_train, k=10, prob=TRUE))
}
model_perceptron <- function(x_train, y_train, x_test) {
per = perceptron(x_train, y_train)
return (predict.perceptron(per, x_test))
}
models = c(model_lda, model_knn1, model_knn5, model_knn10, model_perceptron)
res = sapply(models, function(x) return(CV(x)))
noms = c("lda", "knn1", "knn5", "knn10", "perceptron")
accs = sapply(1:5, function(x) return(mean(res[,x])))
sds = sapply(1:5, function(x) return(sd(res[,x])))
data.frame(noms, accs, sds)
pvalues <- sapply(2:5, function(i) return(t.test(res[,1], res[,i], alternative = "two.sided", var.equal = FALSE)$p.value))
pvalues
data.frame(noms[2:5],pvalues)
x_test = x_split[1][[1]]
y_test = y_split[1][[1]]
x_train = NULL
y_train = NULL
for (el in x_split[-1]){
x_train = rbind(x_train, el)
}
for (el in y_split[-1]){
y_train = c(y_train, el)
}
model <- lda(y_train~., data=x_train)
y_pred = predict(model, newdata=x_test)$class
table(predicted = y_pred, observed = y_test)
sensitivity_score <- function(y_true, y_pred){
TP <- y_true[y_true == y_pred]
TP <- sum(TP[TP==1])
FN <- y_true[y_true != y_pred]
FN <- -sum(FN[FN==-1])
return (TP/(TP+FN))
}
predict_sen <- function(model){
y_pred =as.numeric(as.character( model(x_train, y_train, x_test)))
return (sensitivity_score(y_pred, y_test))
}
res = sapply(models, function(x) return(predict_sen(x)));
data.frame(models = noms, sensitivity=res)
res = res[1:4]
noms[1:4][res==max(res)]
# Visualization of results
accuracy <- c(acc_0, acc_mean, acc_no_na)
names <- c("NA -> 0", "NA -> mean", "removing NA")
#ylim <- c(0, 1.5*max(accuracy))
#ax <- barplot(accuracy,beside=T,col=c("red", "red", "green"), names=names, ylim=ylim,
#              main = "Accuracy of the three models",
#              ylab="Accuracy")
#text(x=ax, y<-accuracy, label=accuracy, pos = 3, cex = 0.8, col = "blue")
data.frame(names, accuracy)
